# 19 fastcapus 강의 듣기

- [ ]  추천시스템 A to Z 듣기
- [ ]  시퀀스 알고리즘 공부
    
    
- [x]  The Red : 우버처럼 사고하기. 완전 수강
    - 빈도 - 불변의 진리가 존재하고 불확실한건 추정량(데이터)이다.
        
        현실적으로는 평행우주를 관찰할 수 없는데?
        
        → 전통적인 통계 - 표본 분포에 대한 수학적 분석 및 증명
        → 시뮬레이션(boostrap) - ‘짝퉁 표본분포 만들기’ 
        
        ⇒ 여러번 반복적으로 resample
        
        - 통계적 정당성(의부재)
        전통적인 “통계적 유의미함”
        - 현실적인 고려 사항
        데이터의 완전성(유용한 정보의 부재)
        확률모형의 현실성(독립성, 확률 적용 가능 등)
        - “좋은”의사결정 $\neq$ 의사결정의 결과
        의사결정이 “좋은”가는, 결과가 나오기 전에 판단 됨.
        의사결정모형을 만드는 이유는 불확실성때문에 의사결정을 함.
        즉, 합리적인 선택을 했느냐의 문제임. 어떤 선택이 더 좋은지의 문제가 아님.
    - 베이지안 - 관심 변수에 대한 믿음(prior), 관찰된 정보의 가능성(likelihood)로 나오는 새로운 믿음(posterior)
        
        연습문제 3번 흥미로움. → 직관적으로 생각한 확률보다 생각보다 다른 결과가 많이 나옴. 따라서 베이지안 확률모형을 사용하는 것은 큰 도움이 됨.
        
        시뮬레이션을 통해 복잡한 사후확률분포(posterior)도 추정가능
        → (Approximate) Computational Bayes
        → $P(p|w) = \frac{P(p)P(w|p)}{C} \propto P(p)P(w|p)$
        
        0과1 사이의 값 → Beta분포를 이용하면 손쉽게 원하는 분포로 설정가능
        
        ```python
        Pymd
        import numpy as np
        imprt pymc3 as pm
        import seaborn as sns
        
        n_obs = 10
        n_android = 6
        
        with pm.Model() as model:
        	p = pm.Beta('p', alpha=1, beta=1)
        	X = pm.Binomial('X', = n=n_obsm p=p, observed=n_android)
        
        with model:
        	posterior = pm.sample(draws=4000, tune=2000)
        ps = posterior.p
        print(len(ps)) # 8000
        
        display(sns.histplot(ps))
        display((ps > .5).mean())
        ```
        
        - 특이 케이스 - Conjugate priors
            
            $P(p) = \frac{p^{(a-1)}(1-p)^{b-1}}{B(a,b)}, P(w|p) = \frac{N!}{s!(N-s)!}p^s(1-p)^{N-s}$
            
            $P(p|w) = \frac{P(p)P(w|p)}{C}$ 
            
            $\propto P(p)P(w|p)$
            
            $\propto p^{(a-1)}(1-p)^{(b-1)}p^s(1-p)^{N-s}$
            
            $\propto p^{(a-1+s)}(1-p)^{(b-1+N-s)}$
            
            $\propto Beta(a+s, b+(N-s))$
            
            ⇒ 빠른 계산 vs 모델의 유연성
            
    - 빈도주의? 베이지안? → 둘다 필요.
        1. 사전접오가 전혀 없다면?
            1. 정말 아무것도 없는가?
        2. 데이터가 압도적으로 많다면?
            1. “극한”의 사전분포 → 데이터가 필요한가?
            2. 다른 사전분포 → 없는거나 마찬가지
        
        베이지안의 강점 - 사전 정보가 중요하고 데이터가 적을 때.
        
        데이터가 아무리 많아도(절대적인 양) specific한 일을 하다보면 데이터가 적은경우는 반드시 오게 되어 있음.
        
        베이지안의 약점 - 정밀하게(precise) 생각하지 못할때. 
        
        - 경험/지식으로 인한 잘못된 편견
        - 문제에 대한 명확하지 못한 이해/분석
        - 분석가(의사결정자)의 능력/판단력이 중요`
        
        포괄적인 접근의 필요
        
        - 빈도주의 기법의 적용 - 상식적으로(사전정보)말이 되는가?
        - 베이지안 기법의 적용 - 분석 과정/결과를 ‘신뢰’할 수 있는가?
        - 공통적인 난제 - “데이터”는 어디로부터 왔는가?
        
        ⇒ 논리적이고 합리적인 과정/결과와 의심을 계속 품어야함.
        
    
    - ML 예측과 인과 관계 분석.
        - 무료 쿠폰을 효과적으로 뿌리는 법?
        - 데이터 소개. - 데이터를 꼼꼼히 살펴보고 꼬치꼬치 캐묻는 것이 업무의 반
        - 예측 모형 - 관측한 정보(데이터)를 기반으로 간측되지 않은 것(미래)에 대한 ‘일반화’ 시도
        - 예측 모형의 오류 - 정보 자체의 불확실성(random noise), 예측 방법으로 인해 발생하는 오류 ⇒ 편향(예측치가 근본적으로 다름), 분산(예측치가 변화에 민감한 정도)
        - Bias-Variance tradeoff
            - 전통적인 통계는 unbiased 예측치를 선호.
            - 실무에서는 결과적인 예측 성능이 중요. 단, bias/variance에 대한 이해가 직관적인 사고에 큰 도움이 됨.
            
            3.3 ipynb 파일 확인해볼것,
            
            sklearn - ColumnTransformer - feature engineering Pipeline
            
            sklearn Pipeline
            
        
    - “데이터, ML”을 거론하기 전에…
        
        ⇒ 목적, 비용, 평가 등 파악해야함. 다른 사람과도 같은 의미인가를 짚어봐야함.
        
        “데이터와 방법”을 논하기 전에 “어떤 결과/정보”를 얻고 싶은가 먼저 대답.
        
        코딩 전, 기대하는 최종 결과(가설)를 먼저 구성.
        
        어떤 형태로든 “인과관계분석”은 피해 갈 수 없다. - 정확한 결과를 도출하는 건 어렵지만 “부정확한”결과도 유용할 때가 많음. 따라서 최소한의 “인과관계분석”에 대한 이해와 내 결점의 오점은 알고 지내야함.
        
    
    3.9 인과관계 분석 기초 → ipynb 확인해 볼것.
    
    - Causal inference의 학풍
        - Rubin - Neyman causl model
            
            → 통계 기반 인과관계 분석법, 관찰되지 못한 결과(잠재적 결과)이 핵심
            
        - Judea Pearl causality
            
            → 데이터/그래프 기반의 분석, 철학적 논쟁이 핵심
            
        - 비교
            
            → 실증적으로 결과적인 계산/결론은 똑같음, 접근법/사고의 차이
            
    - 인과관계란?
        - 인과관계 계산에 필요한 두 관측치 중 하나는 관찰 불가능.
        - 최대한 비슷한 대상을 찾는 등의 방법
        - Average Treatmenmt Effect - 개인적인 효과는 알 수 없지만 어느 집단에 대한 평균적인 효과는 측정이 가능(Average Treatment Effect, ATE)
    - 중요한 가정
        - Selection bias - 처방 여부와 각 결과 간의 상관관계가 없어야함.
            
            → E[쿠폰 결제 여부 | 쿠폰 소지] = E[쿠폰 결제 여부 | 쿠폰 미소지]
            
        - Stable Unit Treatment Value Assumption(SUTVA) - 처방의 종류가 동일
            
            → 최대한 위반하지 않는 설계, 위반하는 경우 결과 해석에 주의.
            
    - 중요한 질문 → 자기의 의견을 말하는 게 중요한게 아니라, 의사결정을 돕기위해서는 이러한 다양한 전제와 가정에 대해 의문을 제기. 그리고 투명성을 부여하는 것이 목적.
        - 전제/가정 파악 - 비지니스 목적/전략에 따라 합당한 이유가 있을 수 있음. 반면 합리적이지 않은 여러가지 이유도 있을 수 있음. → DS의 중요한 역할 중 하나로 다양한 전제/가정에 의문을 제기하여 의사결정 과정에 투명성을 더하는 것,
        - 목적/성과지표 구체화 - 성과지표(metric)의 미묘/복잡한 차이 파악, 외부에서 성과지표가 주어졌을때는, 이에 대해 명확하게 정의/파악, 프로젝트의 궁극적 목적/성공의 척도에 집중
    - ML을 이용한 인과관계 분석의 한계와 주의점
        - 예측 모형을 이용한 ATE 계산
            - 다른 처리를 받은 비슷한 집단을 찾고, 반대의 처리를 계산 해봄,
            - Assuming ignorability(response surface modeling)
                
                “비슷한” 유저는 배정된 것이나 관찰하지 않는 결과의 기대값이 같다 위반 사례 : 관찰하지 않은 ‘미지의 변수(confounder)’가 처리와 상관관계가 있고, 관심 결과와도 상관관계가 있을 경우
                
                ex) 우유 마심(assignment) → 키가 큼(outcome)
                
                ‘우유 마시기 유전자’(confounder)가 존재해도 우유 섭취량과 상관관계를 갖지 않는다면 결과에 영향은 없음.
                
                ‘키크는 유전자’도 outcome과 상관관계가 없으면 영향 없음.
                
                ‘둘다 영향’인 유전자가 존재해도 이에 대한 정보를 관측하지 못한 경우 ignorability 위반 → 인과관계 분석 결과 오류
                
            - 추가 주의 사항
                
                → Treatment assignment 이후에 관측 된 정보 사용.
                
                결제 금액(적용 전) 배송료는 최종 결제 여부와 상관관계 있음. 이를 feature로 포함할 경우, checkout에 대한 예측 성과는 올라가게 됨. 하지만 이는 배송료 무료 쿠폰 지급 이후 관찰한 항목이기 때문에, 이를 포함할 경우 coupon에 대한 인과관계 분석 불가능.
                
                → 사용 예측 모형이 암시하는 바에 대해 주의
                
                대부분 최대한 유연하면서 예측 성과가 우수한 모형(XGBoost)을 사용하면 크게 문제되지 않음. 반면, 문제에 대한 전문적 견해/이해가 있을 경우, 이를 반영할 수 있는 모형 사용이 도움이 될 수 있음
                
        - ML 인과관계 분석
            - 아직 활발하게 연구 되고 있는 분야.
            - 딱히 ‘정답’이나 ‘공식’은 없음.
                
                → 다양한 가정 및 데이터의 기원에 대한 이해 없이 ‘가져다 쓰기’는 잘못된 결과에 이를 위험이 큼
                
            - 다양한 가능성, 가정, 문제에 대한 이해를 바탕으로 판단
            - 비현실적 가정은 피할 수 없음. (현실 반영 복잡 vs 단순 적당 유연)
            - 목적은 ‘완벽함(verisimilitude)’이 아니라 ‘투명/명료함(clarity)’이다.
    - DS의 삶의 근본 가치
        - 호기심과 배우려는 자세
        → ‘내 일’에 대해 방어적이지 않도록 노력, 늘 새로 배울 것 투성이
        - 정밀/정확/명료함
        → 대충 얼버무리고 넘어가면 나중에 고생.
        → 정확하지 않은 것은 ‘모른다’고 인정
        → 정확하지 않아도 괜찮은 것은 의도적/공개적으로 “정확하지 않은 것”을 분명하게 함.
        → 가장 중요한 것은 투명성/명료함(clarity)
        - 유쾌하고 합리적 의심
        → “내가 한거기 떄문에’, “유명한 사람이 한것” 등에 속지 말 것
        → 새로운 문제/해법을 당면했을 때 한발 물러서서 최대한 살펴 볼것
        → 직관적이지 않고 놀라운 일에 현혹되지 말고, 직관이 생길때까지 의심/깊이 있게 탐구 하지만. 모든 과정을 유쾌하고 즐겁게 임할 것. 만사에 불평/의심하는 사람으로 비추기 쉽상.
        - 목적에 대한 초점과 자신감
        → 호기심, 정확도, 의심을 쫓다가 궁극적 목적을 잃기 쉬움.
        → 떄로는 불만족스러운 상황에서의 도전이 필요
        →  “무모한”도전이 아닌, 목적이 분명한 의도적 도전
        →  불확실성에 대한 인정
        - 윤리.
        →  의도치 않게 많은 영향력을 갖기 쉬움
        →  늘 본인의 ‘선’이 무엇인지 미리 고민 - 돈을 벌기위해 나는 어떤 일까지 할것인가? 얼마까지?, 커리에를 위해 무엇까지 포기 할 수 있는. 없는가? 등 DS업무를 하다보면 큰 액수의 의사결정을 도와주다 보니 나도 모르는 사이 영향력을 끼칠 수 있음.(우버에서 차량을 운전한 마일당 차를 운영하는 비용을 예측하는 프로젝트를 사내에서 진행했는데 이후에 미국 전역에서 그 값을 모두 사용하기 시작함. )
        → 본인의 (개인적인) 가치관을 일관적으로 지키기 위한 구체적인 노력이 항시 필요.